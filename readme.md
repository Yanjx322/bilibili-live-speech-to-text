# bilibili.com Live immediate Speech-to-Text (Chinese + English)

åŸºäºBç«™ç›´æ’­çš„å®æ—¶è¯­éŸ³å¬å†™(ä¸­è‹±åŒè¯­ï¼‰

---

## Features / åŠŸèƒ½ä»‹ç»

### Real-time Speech-to-Text for Bilibili Livestreams

- ğŸ”Š **Auto Live Audio Extraction/è‡ªåŠ¨è·å–ç›´æ’­éŸ³é¢‘æµ(bç«™)**\
  Automatically fetches the audio stream from a Bilibili livestream via room ID.

- ğŸŒ **Multilingual Speech Recognition/è‹±æ±‰åŒè¯­è¯†åˆ«**\
  Supports **Chinese** and **English** recognition via Vosk offline models (and experimental HuggingFace models).

- **Integrate different models/æ•´åˆä¸åŒæ¨¡å‹**\
  Including Vosk offline models(trained) + xfyun online models + Huggingface transformers (**state-of-the-art self-supervised learning** model by Facebook AI Meta), which are listed in the [Model Zoo](#model-zoo) below.

- ğŸ› ï¸ **Developer-Friendly WebSocket API/é€šè¿‡websocketå®æ—¶è¾“å‡ºæ¥å£**\
  Exposes a standard WebSocket interface that developers can easily integrate into **web overlays, Python/Node.js services, etc.** Automatic result push over WebSocket for each recognition segment (no polling required)

- ğŸš¨ **Clean & Readable Output/è¯†åˆ«è¾“å‡ºä¼˜åŒ–**\
  Filters out unnecessary pauses, repeated tokens, and space noise for better readability.

## Example feature / ç¤ºä¾‹æ•ˆæœ



![Live Demo]\(./ezgif-1058bfb2b77c30.gif)



---

## ğŸ“ Requirements

- Python 3.10+
- `ffmpeg` installed and in PATH
- Python packages: `vosk`, `transformers`, `soundfile`, `requests`

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ“– Usage

### Step 1: Run the main program

```bash
python main.py
```

### Step 2: Input bilibili live Room ID and Choose Model

```bash
input bilibili room number/è¯·è¾“å…¥Bilibiliç›´æ’­æˆ¿é—´å·: 1

select model/è¯·é€‰æ‹©è¯†åˆ«æ¨¡å‹ï¼š
1. Vosk(Chinese)ç¦»çº¿æ¨¡å‹
2. Vosk(English)ç¦»çº¿æ¨¡å‹
3. xfyunç§‘å¤§è®¯é£åœ¨çº¿æ¨¡å‹
4. Hugging Face wav2vec2-chinese
your input model: 3
```

### Step 3: Start Recognition

```bash
ç›´æ’­æµåœ°å€ï¼šhttps://...
å¼€å§‹è¯†åˆ« (Vosk)...
è¯†åˆ«ç»“æœ: å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°ç›´æ’­é—´
è¯†åˆ«ç»“æœ: Let's begin with today's live
```

---

## Model Zoo

**1. Vosk** has provided more pretrained offline models for different languages, apart from the two given model of this project, download here:

ğŸ”— [https://alphacephei.com/vosk/models](https://alphacephei.com/vosk/models)

for immediate speech-to-text task, I chose 2 small models. Though large models provide more precision, they also reduce speed, causing a delay:

| **Example vosk modelï¼š**       |     |         |                      |
| ----------------------------- | --- | ------- | -------------------- |
| `vosk-model-small-cn-0.22`    | CHN | \~50MB  | small model          |
| `vosk-model-small-en-us-0.15` | ENG | \~40MB  |                      |
| `vosk-model-en-us-0.22`       | ENG | \~1.8GB | more precision, slow |
| `vosk-model-cn-0.22`          | CHN | \~1.8GB |                      |

---

**2. HuggingFace** **Wav2Vec2** is a state-of-the-art **self-supervised speech representation learning model** developed by Facebook AI (Meta). It is trained on raw unlabeled audio and fine-tuned on transcribed speech for tasks like automatic speech recognition (ASR).

Chinese pretrained: [https://huggingface.co/urarik/chinese-wav2vec2-large-CV16](https://huggingface.co/urarik/chinese-wav2vec2-large-CV16)\
English pretrained: [https://huggingface.co/facebook/wav2vec2-base-960h](https://huggingface.co/facebook/wav2vec2-base-960h)

---

**3. xfyunï¼ˆç§‘å¤§è®¯é£ï¼‰Online Speech Recognition**\
xfyun is a powerful cloud-based ASR engine developed by iFLYTEK (ç§‘å¤§è®¯é£), providing real-time speech-to-text conversion with high accuracy for both Chinese and English.\
Unlike offline models, xfyun requires API credentials and Internet connection, and it's suitable for low-latency and high-accuracy live transcription tasks.\
Websiteï¼š[https://www.xfyun.cn/services/online\_asr](https://www.xfyun.cn/services/online_asr)

Usage requires registering an API key on the iFLYTEK open platform, and this project already includes basic integration logic in `xf_recognizer.py`.

---

## ğŸ“‚ Directory Structure

```
project/
â”œâ”€â”€ main.py
â”œâ”€â”€ bilibili_stream.py
â”œâ”€â”€ vosk_recognizer.py
â”œâ”€â”€ vosk_recognizer_English.py
â”œâ”€â”€ model_loader.py
â”œâ”€â”€ xf_recognizer.py
â”œâ”€â”€ hf_recognizer.py
â”œâ”€â”€ requirement.txt
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ vosk-model-small-cn-0.22/
â”‚   â””â”€â”€ vosk-model-small-en-us-0.15/
|    ......
```

---

## ğŸ™ Credits

- [Vosk Speech Recognition](https://alphacephei.com/vosk/)
- [HuggingFace Transformers](https://huggingface.co/models)
- Bilibili Open Platform
